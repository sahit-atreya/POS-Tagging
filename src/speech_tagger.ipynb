{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# IMPORT STATEMENTS\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "from sklearn.model_selection import KFold\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.metrics import precision_recall_fscore_support\r\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\r\n",
    "from sklearn import preprocessing\r\n",
    "le = preprocessing.LabelEncoder()\r\n",
    "\r\n",
    "# if the function is zipped, can use the below libraries to unzip them\r\n",
    "import gzip\r\n",
    "import shutil\r\n",
    "import xml.etree.ElementTree as XET\r\n",
    "\r\n",
    "# these files are from PolEval2017 and contains data fro the task (supervised learning models)\r\n",
    "training_file = '..\\\\data\\\\training.xml'\r\n",
    "validation_file = '..\\\\data\\\\validate.xml'\r\n",
    "testing_file = '..\\\\data\\\\test.xml'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# feature_extraction_from_xml(data_file, orth_or_lemma, ctag_or_full)\r\n",
    "This function is used to extract the orth/lemma and the ctag/full-ctag from the data_file based on the specifications in the second and third arguments\r\n",
    "Returns all the orths/lemmas, ctags/full_ctags, and the number of tokens per chunk (sentence).\r\n",
    "\r\n",
    "Must pass 'orth' or 'lemma' for argument 2\r\n",
    "Must pass 'ctag' or 'full' for argument 3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def feature_extraction(data_file, orth_or_lemma, ctag_or_full):\r\n",
    "    # if (orth_or_lemma != 'orth') or (orth_or_lemma != 'lemma'):\r\n",
    "    #     print(\"Pass the right parameters to orth_or_lemma\")\r\n",
    "    #     return\r\n",
    "    # if (ctag_or_full != 'ctag') or (ctag_or_full != 'full'):\r\n",
    "    #     print(\"Pass the right parameters to ctag_or_full\")\r\n",
    "    #     return\r\n",
    "\r\n",
    "\r\n",
    "    orths = []\r\n",
    "    ctags = []\r\n",
    "    tokens_in_chunk = []\r\n",
    "\r\n",
    "    tree = XET.parse(data_file)\r\n",
    "    root = tree.getroot()\r\n",
    "\r\n",
    "    # highest level tag in the xml (one chunk is one sentence)\r\n",
    "    for chunk in root.findall('chunk'):\r\n",
    "        curr_chunk = 0\r\n",
    "\r\n",
    "        orths.extend([\"_\", \"_\", \"_\"])\r\n",
    "        ctags.extend([\"NONE\", \"NONE\", \"NONE\"])\r\n",
    "        for token in chunk.findall('tok'):\r\n",
    "            if orth_or_lemma == 'orth':\r\n",
    "                orth = token.find('orth').text\r\n",
    "            elif orth_or_lemma == 'lemma':\r\n",
    "                orth = token.find('lex').find('base').text\r\n",
    "\r\n",
    "            if ctag_or_full == 'ctag':\r\n",
    "                ctag = token.find('lex').find('ctag').text.split(':', 1)[0]\r\n",
    "            elif ctag_or_full == 'full':\r\n",
    "                ctag = token.find('lex').find('ctag').text\r\n",
    "            curr_chunk += 1\r\n",
    "\r\n",
    "            orths.append(orth)\r\n",
    "            ctags.append(ctag)\r\n",
    "        orths.extend([\"_\", \"_\", \"_\"])\r\n",
    "        ctags.extend([\"NONE\", \"NONE\", \"NONE\"])\r\n",
    "        tokens_in_chunk.append(curr_chunk)\r\n",
    "    return orths, ctags, tokens_in_chunk"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# need to create data frame that stores all the features and tags (a1-a7 and ctag as columns)\r\n",
    "# create representation of just features\r\n",
    "# fit and predict the features on the ctags from training + validation, then test\r\n",
    "# report results on f1, precision and recall for the Naive Bayes implementation\r\n",
    "# ensure that the data frame creation is a function, as well as anything else so that we can run it on different classifiers.\r\n",
    "\r\n",
    "# main classifiers would be Naive Bayes, Decision Trees, Deep Neural Nets"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def generate_dataframe(orths_or_lemmas, ctags_or_fulls, in_chunks):\r\n",
    "    a1, a2, a3, a4, a5, a6, a7, tags = [], [], [], [], [], [], [], []\r\n",
    "    curr_orth = 3 # keeps track of which orth we are currently in\r\n",
    "\r\n",
    "    # total number of orths/lemmas to iterate through\r\n",
    "    orths_count = len(orths_or_lemmas)\r\n",
    "\r\n",
    "    for i in range(len(in_chunks)):\r\n",
    "        for j in range(curr_orth, (curr_orth + in_chunks[i])):\r\n",
    "            a1.append(orths_or_lemmas[j-3])\r\n",
    "            a2.append(orths_or_lemmas[j-2])\r\n",
    "            a3.append(orths_or_lemmas[j-1])\r\n",
    "            a4.append(orths_or_lemmas[j])\r\n",
    "            a5.append(orths_or_lemmas[j+1])\r\n",
    "            a6.append(orths_or_lemmas[j+2])\r\n",
    "            a7.append(orths_or_lemmas[j+3])\r\n",
    "            tags.append(ctags_or_fulls[j])\r\n",
    "            curr_orth += 1\r\n",
    "        curr_orth += 6\r\n",
    "\r\n",
    "    total_tag_size = len(tags)\r\n",
    "    df = pd.DataFrame(list(zip(a1, a2, a3, a4, a5, a6, a7, tags)), columns=['a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', 'class'])\r\n",
    "\r\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Uses sklearns preprocessor for label encoding\r\n",
    "df is for the dataframe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def labels_and_forFitting(df):\r\n",
    "    labels = np.asarray(df['class'].astype(\"category\").cat.codes.tolist())\r\n",
    "    values = df.drop(columns=['class']).values # represents just the features\r\n",
    "    le.fit(values.ravel()) # assigns numeric codes for unique values in values\r\n",
    "\r\n",
    "    to_return = le.transform(values.ravel()) # convert features to numeric codes\r\n",
    "    to_return = to_return.reshape(values.shape[0], -1) # reshape back to old shape\r\n",
    "\r\n",
    "    return labels, to_return"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def buildClassifiers(clf, X_train, X_test, y_train, y_test):\r\n",
    "    # The fit function trains the model (clf)\r\n",
    "    # X_train is a 2d array of the features: each row represents a datapoint, each column represents a feature\r\n",
    "    # y_train is a 1d array of labels. The nth value of the array is the label for the nth row in X_train\r\n",
    "    clf.fit(X_train, y_train)\r\n",
    "    \r\n",
    "    # generating predictions for unseen data\r\n",
    "    y_pred = clf.predict(X_test)\r\n",
    "\r\n",
    "    # calculate the precision, recall and f1 scores to evaluate the classifiers performance on the test data\r\n",
    "    f1 = f1_score(y_test, y_pred, average=\"micro\")\r\n",
    "    precision = precision_score(y_test, y_pred, average=\"micro\")\r\n",
    "    recall = recall_score(y_test, y_pred, average=\"micro\")\r\n",
    "\r\n",
    "    return f1, precision, recall"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following block is used to see if the models work as they should. Training is used to train the model, which is then validated using the validation set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "orths_train, ctags_train, in_chunks_train = feature_extraction(training_file, 'orth', 'ctag')\r\n",
    "df_train = generate_dataframe(orths_train, ctags_train, in_chunks_train)\r\n",
    "labels_train, trained_vals = labels_and_forFitting(df_train)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m orths_train, ctags_train, in_chunks_train \u001b[38;5;241m=\u001b[39m feature_extraction(training_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mctag\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m df_train \u001b[38;5;241m=\u001b[39m generate_dataframe(orths_train, ctags_train, in_chunks_train)\n\u001b[1;32m----> 3\u001b[0m labels_train, trained_vals \u001b[38;5;241m=\u001b[39m \u001b[43mlabels_and_forFitting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36mlabels_and_forFitting\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlabels_and_forFitting\u001b[39m(df):\n\u001b[1;32m----> 2\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcat\u001b[38;5;241m.\u001b[39mcodes\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m      3\u001b[0m     values \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;66;03m# represents just the features\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     le \u001b[38;5;241m=\u001b[39m preprocessing\u001b[38;5;241m.\u001b[39mLabelEncoder()\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.12 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "009c6260f8c949f949e8d5c80e91b7d11da42068722b763148e110eb4d6efd9c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}